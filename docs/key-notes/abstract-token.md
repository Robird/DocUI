## 面临的挑战
不同模型采用的分词器不同，并且有的不开放。这为在同一份上下文上切换模型带来了准确获得特定模型下的token数的困难。
由于注意力稀释和计费等多层面的原因，有效上下文长度小于甚至远小于最大上下文窗口长度。

## 解决对策
放弃准确计量特定模型下的上下文Token计数，转而估算一种跨模型的上下文信息本身的抽象信息量，并使其单位大致与主流分词器Token相当。单位暂定称为Abstract-Token。

## 候选的Abstract-Token计量方式：
1. 逐字符统计目标文本的字符类别，然后线性加权得到Abstract-Token数。加权系数来自对主流模型在标准语料库在上的Token数的拟合。优点是特别快，逻辑简单，缺点是并不分词从而使得有些边缘情况会出现偏差较大的结果。
2. 选定一种先进开源分词器，用其分词结果作为Abstract-Token计量。

## TODO
对比和选择最终采用的Abstract-Token计量方式。
